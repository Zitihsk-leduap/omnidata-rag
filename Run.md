# How to run the project

This project runs LLMs locally using **Ollama** inside Docker

## Prerequisites
- Docker
- Dokcer Compose

## Steps to Run

### 1. Start Ollama
    ``` bash
    docker compose -f Docker/docker-commose.yml up

